{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "ff6d16ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://thor.robots.ox.ac.uk/datasets/flowers-102/102flowers.tgz to flower-102\\train\\flowers-102\\102flowers.tgz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████| 344862509/344862509 [00:31<00:00, 10974774.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting flower-102\\train\\flowers-102\\102flowers.tgz to flower-102\\train\\flowers-102\n",
      "Downloading https://thor.robots.ox.ac.uk/datasets/flowers-102/imagelabels.mat to flower-102\\train\\flowers-102\\imagelabels.mat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 502/502 [00:00<00:00, 505653.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://thor.robots.ox.ac.uk/datasets/flowers-102/setid.mat to flower-102\\train\\flowers-102\\setid.mat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████| 14989/14989 [00:00<00:00, 15025913.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://thor.robots.ox.ac.uk/datasets/flowers-102/102flowers.tgz to flower-102\\val\\flowers-102\\102flowers.tgz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████| 344862509/344862509 [00:31<00:00, 10800863.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting flower-102\\val\\flowers-102\\102flowers.tgz to flower-102\\val\\flowers-102\n",
      "Downloading https://thor.robots.ox.ac.uk/datasets/flowers-102/imagelabels.mat to flower-102\\val\\flowers-102\\imagelabels.mat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 502/502 [00:00<00:00, 506261.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://thor.robots.ox.ac.uk/datasets/flowers-102/setid.mat to flower-102\\val\\flowers-102\\setid.mat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████| 14989/14989 [00:00<00:00, 15054698.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://thor.robots.ox.ac.uk/datasets/flowers-102/102flowers.tgz to flower-102\\test\\flowers-102\\102flowers.tgz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████| 344862509/344862509 [00:29<00:00, 11641807.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting flower-102\\test\\flowers-102\\102flowers.tgz to flower-102\\test\\flowers-102\n",
      "Downloading https://thor.robots.ox.ac.uk/datasets/flowers-102/imagelabels.mat to flower-102\\test\\flowers-102\\imagelabels.mat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 502/502 [00:00<00:00, 506261.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://thor.robots.ox.ac.uk/datasets/flowers-102/setid.mat to flower-102\\test\\flowers-102\\setid.mat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 14989/14989 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "import torchvision.datasets as datasets\n",
    "import torch\n",
    "from torch import nn\n",
    "import ml_collections\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Download dataset\n",
    "train_data = datasets.Flowers102(root='./flower-102/train', split='train', download=True)\n",
    "val_data = datasets.Flowers102(root='./flower-102/val', split='val', download=True)\n",
    "test_data = datasets.Flowers102(root='./flower-102/test', split='test', download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c4396b",
   "metadata": {},
   "source": [
    "### Model Implementations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "id": "2118089a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of available pretrained resnets from pytorch\n",
    "class Pretrains():\n",
    "    resnet_versions = [\n",
    "        'resnet18',\n",
    "        'resnet34',\n",
    "        'resnet50',\n",
    "        'resnet101',\n",
    "        'resnet152'\n",
    "    ]\n",
    "    vgg_versions = [\n",
    "        'vgg11',\n",
    "        'vgg11_bn',\n",
    "        'vgg13',\n",
    "        'vgg13_bn',\n",
    "        'vgg16',\n",
    "        'vgg16_bn',\n",
    "        'vgg19',\n",
    "        'vgg19_bn'\n",
    "    ]\n",
    "\n",
    "class PretrainBackbone(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(ResNetBackbone, self).__init__()\n",
    "        \n",
    "        # Load pretrained ResNet/VGG backbone\n",
    "        if config.pretrain in Pretrains.resnet_versions or config.resnet_version in Pretrains.vgg_versions:\n",
    "            model = torch.hub.load('pytorch/vision:v0.10.0', config.pretrain, pretrained=True)\n",
    "        else:\n",
    "            raise ValueError('Invalid ResNet/VGG Version. Please select from: ' \n",
    "                             + ', '.join(Pretrains.resnet_versions + Pretrains.vgg_versions))\n",
    "        \n",
    "        # Segments out only the backbone layers as list, unpacks, and load into nn.Sequential\n",
    "        backbone_layers = list(model.children())[:-1]\n",
    "        self.backbone = nn.Sequential(*backbone_layers)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)\n",
    "        return x\n",
    "\n",
    "class ActivationFunction(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(ActivationFunction, self).__init__()\n",
    "        match config.type:\n",
    "            case 'LeakyReLU':\n",
    "                self.activation_func = nn.LeakyReLU(\n",
    "                    config.negative_slope,\n",
    "                    inplace = True\n",
    "                )\n",
    "            case 'ReLU':\n",
    "                self.activation_func = nn.ReLU(inplace = True)\n",
    "            case 'Softmax':\n",
    "                self.activation_func = nn.Softmax(dim = self.dim)\n",
    "            case _:\n",
    "                raise ValueError('Invalid activation function or not implemented')\n",
    "    def forward(self, x):\n",
    "        return self.activation_func(x)\n",
    "\n",
    "class Conv2dBlock(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(Conv2dBlock, self).__init__()\n",
    "        modules = []\n",
    "        if config.layer_num < 1:\n",
    "            raise ValueError('Number of layers cannot be less than 1')\n",
    "        for layer_idx in range(config.layer_num):\n",
    "            # Conv2d\n",
    "            modules.append(nn.Conv2d(\n",
    "                config.in_channels if not layer_idx else config.out_channels,\n",
    "                config.out_channels,\n",
    "                kernel_size = 3,\n",
    "                padding = 1\n",
    "            ))\n",
    "            \n",
    "            # Batch Normalization\n",
    "            if config.use_batchnorm:\n",
    "                modules.append(nn.BatchNorm2d(config.out_channels))\n",
    "                \n",
    "            # Activation function, skip this step if skip_last_activation is True\n",
    "            if config.skip_last_activation and layer_idx == config.layer_num - 1:\n",
    "                break   \n",
    "            modules.append(ActivationFunction(config.activation_func))\n",
    "        self.sequential = nn.Sequential(*modules)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.sequential(x)\n",
    "\n",
    "# Creates a mirrored Conv2dBlock\n",
    "class RevConv2dBlock(nn.Module):\n",
    "    def __init__(self, conv2d_block):\n",
    "        super(RevConv2dBlock, self).__init__()\n",
    "        \n",
    "        # Reverses module from conv2d_block\n",
    "        modules = list(conv2d_block.sequential)\n",
    "        modules.reverse()\n",
    "        module_iterator = iter(range(len(modules)))\n",
    "        for idx in module_iterator:\n",
    "            if isinstance(modules[idx], torch.nn.modules.batchnorm.BatchNorm2d):\n",
    "                \n",
    "                # Switch order of batch and conv2d\n",
    "                modules[idx], modules[idx + 1] = modules[idx + 1], modules[idx]\n",
    "                \n",
    "                # Swap conv2d with convtranspose2d\n",
    "                modules[idx] = nn.ConvTranspose2d(\n",
    "                    modules[idx].out_channels,\n",
    "                    modules[idx].in_channels,\n",
    "                    kernel_size = modules[idx].kernel_size,\n",
    "                    stride = modules[idx].stride,\n",
    "                    padding = modules[idx].padding\n",
    "                )\n",
    "                \n",
    "                modules[idx + 1] = nn.BatchNorm2d(modules[idx].out_channels)\n",
    "                \n",
    "                # Skip next index\n",
    "                next(module_iterator)\n",
    "            \n",
    "        if isinstance(modules[0], ActivationFunction):\n",
    "            activation_func = modules.pop(0)\n",
    "            modules.append(activation_func)\n",
    "            \n",
    "        self.sequential = nn.Sequential(*modules)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.sequential(x)\n",
    "    \n",
    "class VGGBackboneBlock(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(VGGBackboneBlock, self).__init__()\n",
    "        config.skip_last_activation = False\n",
    "        \n",
    "        # Conv2d\n",
    "        self.conv2d_block = Conv2dBlock(config)\n",
    "        \n",
    "        # Maxpool\n",
    "        self.maxpool = nn.MaxPool2d(\n",
    "            kernel_size=config.compression_ratio, \n",
    "            stride=config.compression_ratio\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.conv2d_block(x)\n",
    "        out = self.maxpool(out)\n",
    "        return out\n",
    "    \n",
    "    def get_reverse(self):\n",
    "        return RevVGGBackconeBlock(self)\n",
    "    \n",
    "class RevVGGBackconeBlock(nn.Module):\n",
    "    def __init__(self, vgg_backbone_block):\n",
    "        super(VGGBackboneBlock).__init__()\n",
    "        # To be implemented\n",
    "    def forward(self, x):\n",
    "        # To be implemented\n",
    "        return x\n",
    "    \n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        \n",
    "        # Main Conv2d block\n",
    "        main_block_config = config\n",
    "        main_block_config.layer_num = config.main_layer_num\n",
    "        main_block_config.skip_last_activation = True\n",
    "        self.main_block = Conv2dBlock(main_block_config)\n",
    "        \n",
    "        # Shortcut Conv2d block, we leave self.shortcut_block as undefined if shortcut layer depth = 0\n",
    "        if config.shortcut_layer_num:\n",
    "            shortcut_block_config = config\n",
    "            shortcut_block_config.layer_num = config.shortcut_layer_num\n",
    "            shortcut_block_config.skip_last_activation = True\n",
    "            self.shortcut_block = Conv2dBlock(shortcut_block_config)\n",
    "            \n",
    "        self.activation_func = ActivationFunction(config.activation_func)\n",
    "        \n",
    "        # Optional maxpooling layer if compression_ratio is set\n",
    "        if hasattr(config, 'compression_ratio'):\n",
    "            self.maxpool = nn.MaxPool2d(\n",
    "                kernel_size=config.compression_ratio, \n",
    "                stride=config.compression_ratio\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.main_block(x)\n",
    "        if hasattr(self, 'shortcut_block'):\n",
    "            out += self.shortcut_block(x)\n",
    "        else:\n",
    "            out += x\n",
    "            \n",
    "        out = self.activation_func(out)\n",
    "            \n",
    "        if hasattr(self, 'maxpool'):\n",
    "            out = self.maxpool(out)\n",
    "            \n",
    "        return out\n",
    "\n",
    "    def get_reverse(self):\n",
    "        # Get reversed version\n",
    "        return RevResidualBlock(self)\n",
    "\n",
    "class RevResidualBlock(nn.Module):\n",
    "    def __init__(self, residual_block):\n",
    "        super(RevResidualBlock, self).__init__()\n",
    "        self.main_block = RevConv2dBlock(residual_block.main_block)\n",
    "        \n",
    "        if hasattr(residual_block, 'shortcut_block'):\n",
    "            self.shortcut_block = RevConv2dBlock(residual_block.shortcut_block)\n",
    "            \n",
    "        if hasattr(residual_block, 'maxpool'):\n",
    "            self.upsample = nn.Upsample(scale_factor=residual_block.maxpool.stride)\n",
    "            \n",
    "    def forward(self, x):\n",
    "        if hasattr(self, 'upsample'):\n",
    "            x = self.upsample(x)\n",
    "        else:\n",
    "            x = x\n",
    "            \n",
    "        out = self.main_block(x)\n",
    "        \n",
    "        if hasattr(self, 'shortcut_block'):\n",
    "            out += self.shortcut_block(x)\n",
    "        else:\n",
    "            out += x\n",
    "        return out\n",
    "    \n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(Encoder, self).__init__()\n",
    "        modules = []\n",
    "        match config.type:\n",
    "            case 'residual_blocks':\n",
    "                for idx, block_feature in enumerate(config.features):\n",
    "                    if not idx:\n",
    "                        in_channels = config.in_channels\n",
    "                        out_channels = block_feature\n",
    "                    else:\n",
    "                        in_channels = config.features[idx - 1]\n",
    "                        out_channels = block_feature\n",
    "\n",
    "                    block_config = ml_collections.ConfigDict({\n",
    "                        'main_layer_num': config.main_layer_num,\n",
    "                        'shortcut_layer_num': config.shortcut_layer_num,\n",
    "                        'in_channels': in_channels,\n",
    "                        'out_channels': out_channels,\n",
    "                        'use_batchnorm': config.use_batchnorm,\n",
    "                        'activation_func': config.activation_func,\n",
    "                    })\n",
    "                    if hasattr(config, 'compression_ratio'):\n",
    "                        block_config.compression_ratio = config.compression_ratio\n",
    "\n",
    "                    modules.append(ResidualBlock(block_config))\n",
    "            case 'vgg_backbone_blocks':\n",
    "                # To be implemented\n",
    "                raise NotImplementedError('To be implemented')\n",
    "                \n",
    "        self.sequential = nn.Sequential(*modules)\n",
    "    def forward(self, x):\n",
    "        return self.sequential(x)\n",
    "        \n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, arg):\n",
    "        super(Decoder, self).__init__()\n",
    "        # Initialize by mirroring encoder\n",
    "        if isinstance(arg, Encoder):\n",
    "            encoder = arg\n",
    "            modules = list(encoder.sequential)\n",
    "            modules.reverse()\n",
    "            \n",
    "            for idx in range(len(modules)):\n",
    "                modules[idx] = modules[idx].get_reverse()\n",
    "            self.sequential = nn.Sequential(*modules)\n",
    "        # Initialize by config (not implemented since we are using mirrored encoder/decoder)\n",
    "        else:\n",
    "            raise NotImplementedError('This decoder class is only implemented to be initialized by mirroring an encoder class')\n",
    "    def forward(self, x):\n",
    "        return self.sequential(x)\n",
    "    \n",
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "        # Encoder\n",
    "        encoder_config = config.encoder_config\n",
    "        encoder_config.in_channels = config.in_channels\n",
    "        self.encoder = Encoder(encoder_config)\n",
    "        \n",
    "        # Check for bottleneck input size by passing dummy input to encoder\n",
    "        dummy_input = torch.randn(1, config.in_channels, config.in_dimension[0], config.in_dimension[1])\n",
    "        out = self.encoder.forward(dummy_input)\n",
    "        out_dimension = list(out.size())\n",
    "        in_bottleneck = out_dimension[1] * out_dimension[2] * out_dimension[3]\n",
    "        \n",
    "        # Bottleneck\n",
    "        self.bottleneck = nn.Linear(in_bottleneck, config.bottleneck_width)\n",
    "        \n",
    "        # Decoder\n",
    "        self.decoder = Decoder(self.encoder)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.encoder(x)\n",
    "        encoder_out_shape = out.size() \n",
    "        flatten = out.view(out.size(0), -1)\n",
    "        out = self.bottleneck(flatten)\n",
    "        reshaped = out.view(out.size()[0], out.size()[1], 1, 1)\n",
    "        out = self.decoder(reshaped)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e2da68",
   "metadata": {},
   "source": [
    "### Test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "ccd0338d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.5516, -0.2068, -0.4680,  ..., -0.8531, -0.4450,  0.1232],\n",
       "          [ 0.8301,  0.7162,  0.5984,  ..., -1.5186, -0.2426, -0.2329],\n",
       "          [ 0.8712,  1.0302,  1.0262,  ..., -0.5684,  0.7226,  0.5514],\n",
       "          ...,\n",
       "          [ 1.0588,  0.4694,  0.0622,  ...,  1.3015,  1.8702,  1.1376],\n",
       "          [ 1.1240,  0.0624, -0.1162,  ...,  1.1003,  1.2729,  1.0246],\n",
       "          [ 1.2998,  0.0777,  0.1123,  ...,  0.6273,  0.9946,  0.2985]],\n",
       "\n",
       "         [[ 0.0466,  0.8038,  0.8825,  ...,  0.8605,  0.5045,  0.8763],\n",
       "          [ 0.4250, -0.4446, -0.6750,  ...,  0.5111, -0.1032,  0.2369],\n",
       "          [-0.1207, -0.9937, -0.6350,  ...,  0.9737, -0.2861,  0.0639],\n",
       "          ...,\n",
       "          [ 1.1805,  1.4365,  1.4348,  ..., -0.0631, -0.1165,  0.6880],\n",
       "          [ 0.2076,  0.7495,  0.7422,  ...,  0.1660, -0.2923,  0.7185],\n",
       "          [-0.1095,  0.4830,  0.3474,  ..., -0.5860, -0.7834,  0.4724]],\n",
       "\n",
       "         [[-0.7530, -0.1011, -0.5831,  ..., -1.1542, -1.1337, -0.6581],\n",
       "          [ 0.0807,  0.0728, -0.3395,  ..., -0.2891, -0.8982, -0.8888],\n",
       "          [ 0.3040,  0.6055,  0.6394,  ..., -0.4869, -0.3255, -0.8409],\n",
       "          ...,\n",
       "          [-0.7113, -0.4473, -0.5902,  ..., -2.5433, -2.4858, -2.0015],\n",
       "          [-0.6829, -0.3645, -0.8601,  ..., -2.1493, -1.9289, -1.0697],\n",
       "          [-0.7774, -0.6079,  0.1020,  ..., -1.1192, -1.0699, -0.7661]]]],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_dict = {\n",
    "    'in_dimension': (224, 224),\n",
    "    'in_channels': 3,\n",
    "    'encoder_config': {\n",
    "        'type': 'residual_blocks',\n",
    "        'compression_ratio': 2,\n",
    "        'features': [64, 128, 256, 512, 512, 512],\n",
    "        'main_layer_num': 3,\n",
    "        'shortcut_layer_num': 1,\n",
    "        'use_batchnorm': True,\n",
    "        'activation_func': {\n",
    "            'type': 'LeakyReLU',\n",
    "            'negative_slope': 0.1\n",
    "        },\n",
    "    },\n",
    "    'decoder_config': {\n",
    "        'mirror_encoder': True\n",
    "    },\n",
    "    'bottleneck_width': 512\n",
    "}\n",
    "test_config = ml_collections.ConfigDict(config_dict)\n",
    "\n",
    "autoencoder = AutoEncoder(test_config)\n",
    "autoencoder.forward(torch.randn(1, 3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "c8f2f61a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset Flowers102\n",
       "    Number of datapoints: 1020\n",
       "    Root location: ./flower-102/train\n",
       "    split=train"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc269a0e",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "id": "d3505c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "# All hyperparameters to be tuned for the autoencoder network\n",
    "configs_dict = {\n",
    "    'in_dimension': [(224, 224)],\n",
    "    'in_channels': [3],\n",
    "    'encoder_config': {\n",
    "        'type': ['residual_blocks'],\n",
    "        'compression_ratio': [2],\n",
    "        'features': [\n",
    "            [64, 128, 256, 512, 512, 512],\n",
    "            [64, 128, 256, 512, 512],\n",
    "            [64, 128, 256],\n",
    "            [32, 64, 128, 256, 512, 512, 512],\n",
    "            [32, 64, 128, 256, 512, 512],\n",
    "            [32, 64, 128, 256, 512],\n",
    "            [16, 32, 64, 128, 256, 512, 512],\n",
    "            [16, 32, 64, 128, 256, 512],\n",
    "            [16, 32, 64, 128, 256],\n",
    "        ],\n",
    "        'main_layer_num': [2, 1],\n",
    "        'shortcut_layer_num': [1, 0],\n",
    "        'use_batchnorm': [True, False],\n",
    "        'activation_func':[\n",
    "            {\n",
    "                'type': 'LeakyReLU',\n",
    "                'negative_slope': 0.1\n",
    "            },\n",
    "            {\n",
    "                'type': 'LeakyReLU',\n",
    "                'negative_slope': 0.2\n",
    "            },\n",
    "            {\n",
    "                'type': 'ReLU',\n",
    "            }\n",
    "        ] \n",
    "            \n",
    "    },\n",
    "    'decoder_config': {\n",
    "        'mirror_encoder': [True]\n",
    "    },\n",
    "    'bottleneck_width': [256, 512, 1024, 2048]\n",
    "}\n",
    "\n",
    "# Parse ConfigDict with hyperparameters to be tuned and output list of all ConfigDicts to be tested\n",
    "def generate_configs(configs):\n",
    "    config_list = [ml_collections.ConfigDict()]\n",
    "    for key in configs:\n",
    "        new_config_list = []\n",
    "        \n",
    "        current_key_configs = []\n",
    "        if isinstance(configs[key], list):\n",
    "            current_key_configs = configs[key]\n",
    "        elif isinstance(configs[key], ml_collections.config_dict.config_dict.ConfigDict):\n",
    "            current_key_configs = generate_configs(configs[key])\n",
    "        else:\n",
    "            raise TypeError(configs[key] + ' is neither a list nor an ml_collections.ConfigDict object')\n",
    "#         print(key, current_key_configs)\n",
    "        for key_config in current_key_configs:\n",
    "            for prev_config in config_list:\n",
    "                prev_config_copy = copy.deepcopy(prev_config)\n",
    "                prev_config_copy[key] = key_config\n",
    "                new_config_list.append(prev_config_copy)\n",
    "        config_list = new_config_list\n",
    "    return config_list\n",
    "\n",
    "config_list = generate_configs(configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "id": "9e06a76c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "864\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "bottleneck_width: 256\n",
       "decoder_config:\n",
       "  mirror_encoder: true\n",
       "encoder_config:\n",
       "  activation_func:\n",
       "    negative_slope: 0.1\n",
       "    type: LeakyReLU\n",
       "  compression_ratio: 2\n",
       "  features:\n",
       "  - 64\n",
       "  - 128\n",
       "  - 256\n",
       "  - 512\n",
       "  - 512\n",
       "  - 512\n",
       "  in_channels: 3\n",
       "  main_layer_num: 2\n",
       "  shortcut_layer_num: 1\n",
       "  type: residual_blocks\n",
       "  use_batchnorm: true\n",
       "in_channels: 3\n",
       "in_dimension: !!python/tuple\n",
       "- 224\n",
       "- 224"
      ]
     },
     "execution_count": 447,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(config_list))\n",
    "config_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164548ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "334ac959",
   "metadata": {},
   "source": [
    "### WIP Stuffs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
